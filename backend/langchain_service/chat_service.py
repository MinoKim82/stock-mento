"""
LangChainì„ í™œìš©í•œ AI ì±—ë´‡ ì„œë¹„ìŠ¤
OpenAI GPTì™€ Google Geminië¥¼ ì§€ì›í•©ë‹ˆë‹¤.
"""
import os
import json
from typing import List, Dict, Optional, Literal, Any
from dataclasses import dataclass, asdict
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# LangChain imports
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.documents import Document
from langchain_community.document_loaders import TextLoader

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

@dataclass
class Message:
    """ì±„íŒ… ë©”ì‹œì§€ ë°ì´í„° í´ë˜ìŠ¤"""
    role: Literal["user", "assistant", "system"]
    content: str
    timestamp: Optional[str] = None
    
    def __post_init__(self):
        """íƒ€ì„ìŠ¤íƒ¬í”„ ìë™ ì„¤ì •"""
        if self.timestamp is None:
            self.timestamp = datetime.now().isoformat()

class ChatService:
    """AI ì±—ë´‡ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        provider: Literal["openai", "gemini"] = "gemini",
        model: Optional[str] = None,
        temperature: float = 0.7,
        system_prompt: Optional[str] = None,
        session_id: Optional[str] = None,
        storage_dir: Optional[str] = None
    ):
        """
        ChatService ì´ˆê¸°í™”
        
        Args:
            provider: AI ì œê³µì ("openai" ë˜ëŠ” "gemini")
            model: ì‚¬ìš©í•  ëª¨ë¸ëª… (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
            temperature: ìƒì„± ì˜¨ë„ (0.0 ~ 1.0)
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            session_id: ì„¸ì…˜ ID (ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ìš©)
            storage_dir: ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.provider = provider or os.getenv("AI_PROVIDER", "gemini")
        self.temperature = temperature
        self.system_prompt = system_prompt or self._get_default_system_prompt()
        self.session_id = session_id or self._generate_session_id()
        
        # ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if storage_dir:
            self.storage_dir = Path(storage_dir)
        else:
            # ê¸°ë³¸: backend/chat_history/
            backend_dir = Path(__file__).parent.parent
            self.storage_dir = backend_dir / "chat_history"
        
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
        # LLM ì´ˆê¸°í™”
        self.llm = self._initialize_llm(model)
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬
        self.chat_history: List[Message] = []
        
        # ì €ì¥ëœ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¡œë“œ
        self._load_history()
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
        self.prompt = self._create_prompt_template()
        
        # Chain ìƒì„±
        self.chain = self._create_chain()
    
    def _generate_session_id(self) -> str:
        """ì„¸ì…˜ ID ìƒì„±"""
        return datetime.now().strftime("%Y%m%d_%H%M%S")
    
    def _get_history_file_path(self) -> Path:
        """íˆìŠ¤í† ë¦¬ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
        return self.storage_dir / f"chat_{self.session_id}.json"
    
    def _load_history(self):
        """ì €ì¥ëœ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¡œë“œ"""
        history_file = self._get_history_file_path()
        
        if history_file.exists():
            try:
                with open(history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                # JSONì„ Message ê°ì²´ë¡œ ë³€í™˜
                self.chat_history = [
                    Message(
                        role=msg['role'],
                        content=msg['content'],
                        timestamp=msg.get('timestamp')
                    )
                    for msg in data.get('messages', [])
                ]
                
                print(f"âœ… ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¡œë“œ ì™„ë£Œ: {len(self.chat_history)}ê°œ ë©”ì‹œì§€")
            except Exception as e:
                print(f"âš ï¸ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                self.chat_history = []
        else:
            print(f"ğŸ“ ìƒˆë¡œìš´ ëŒ€í™” ì„¸ì…˜ ì‹œì‘: {self.session_id}")
    
    def _save_history(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ íŒŒì¼ì— ì €ì¥"""
        history_file = self._get_history_file_path()
        
        try:
            # Message ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            messages_dict = [
                {
                    'role': msg.role,
                    'content': msg.content,
                    'timestamp': msg.timestamp
                }
                for msg in self.chat_history
            ]
            
            data = {
                'session_id': self.session_id,
                'provider': self.provider,
                'created_at': self.chat_history[0].timestamp if self.chat_history else datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat(),
                'message_count': len(self.chat_history),
                'messages': messages_dict
            }
            
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            # print(f"ğŸ’¾ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ ì™„ë£Œ: {len(self.chat_history)}ê°œ ë©”ì‹œì§€")
        except Exception as e:
            print(f"âš ï¸ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def _get_default_system_prompt(self) -> str:
        """ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
        return """ë‹¹ì‹ ì€ ì£¼ì‹ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³ , íˆ¬ì ì „ëµì— ëŒ€í•œ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” ì—­í• :
1. í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ë¶„ì„
2. ìì‚° ë°°ë¶„ ì¡°ì–¸
3. ìœ„í—˜ ê´€ë¦¬ ì „ëµ ì œì•ˆ
4. íˆ¬ì ì„±ê³¼ í‰ê°€

í•­ìƒ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ë©°, íˆ¬ì ì¡°ì–¸ì€ ì°¸ê³ ìš©ì„ì„ ëª…ì‹œí•©ë‹ˆë‹¤."""
    
    def _initialize_llm(self, model: Optional[str]):
        """LLM ì´ˆê¸°í™”"""
        if self.provider == "openai":
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            model_name = model or "gpt-4o-mini"
            return ChatOpenAI(
                api_key=api_key,
                model=model_name,
                temperature=self.temperature
            )
        
        elif self.provider == "gemini":
            api_key = os.getenv("GOOGLE_API_KEY")
            if not api_key:
                raise ValueError("GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # Gemini 2.5 Flash ëª¨ë¸ ì‚¬ìš©
            model_name = model or "gemini-2.0-flash-exp"
            return ChatGoogleGenerativeAI(
                google_api_key=api_key,
                model=model_name,
                temperature=self.temperature,
                convert_system_message_to_human=True  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë³€í™˜
            )
        
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” provider: {self.provider}")
    
    def _create_prompt_template(self) -> ChatPromptTemplate:
        """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±"""
        return ChatPromptTemplate.from_messages([
            ("system", self.system_prompt),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}")
        ])
    
    def _create_chain(self):
        """LangChain Chain ìƒì„±"""
        return (
            {
                "chat_history": lambda x: self._format_chat_history(),
                "input": RunnablePassthrough()
            }
            | self.prompt
            | self.llm
            | StrOutputParser()
        )
    
    def _format_chat_history(self) -> List:
        """ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ LangChain ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        messages = []
        for msg in self.chat_history:
            if msg.role == "user":
                messages.append(HumanMessage(content=msg.content))
            elif msg.role == "assistant":
                messages.append(AIMessage(content=msg.content))
            elif msg.role == "system":
                messages.append(SystemMessage(content=msg.content))
        return messages
    
    def chat(self, user_message: str) -> str:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë°›ì•„ AI ì‘ë‹µ ìƒì„±
        
        Args:
            user_message: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            
        Returns:
            AI ì‘ë‹µ ë©”ì‹œì§€
        """
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.chat_history.append(Message(role="user", content=user_message))
        
        # AI ì‘ë‹µ ìƒì„±
        response = self.chain.invoke(user_message)
        
        # AI ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.chat_history.append(Message(role="assistant", content=response))
        
        # íˆìŠ¤í† ë¦¬ ì €ì¥
        self._save_history()
        
        return response
    
    async def achat(self, user_message: str) -> str:
        """
        ë¹„ë™ê¸° ì±„íŒ… (ìŠ¤íŠ¸ë¦¬ë° ì§€ì›)
        
        Args:
            user_message: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            
        Returns:
            AI ì‘ë‹µ ë©”ì‹œì§€
        """
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.chat_history.append(Message(role="user", content=user_message))
        
        # AI ì‘ë‹µ ìƒì„±
        response = await self.chain.ainvoke(user_message)
        
        # AI ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.chat_history.append(Message(role="assistant", content=response))
        
        # íˆìŠ¤í† ë¦¬ ì €ì¥
        self._save_history()
        
        return response
    
    async def stream_chat(self, user_message: str):
        """
        ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ AI ì‘ë‹µ ìƒì„±
        
        Args:
            user_message: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            
        Yields:
            AI ì‘ë‹µ í† í°
        """
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.chat_history.append(Message(role="user", content=user_message))
        
        # AI ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ìƒì„±
        full_response = ""
        async for chunk in self.chain.astream(user_message):
            full_response += chunk
            yield chunk
        
        # ì™„ì „í•œ ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.chat_history.append(Message(role="assistant", content=full_response))
        
        # íˆìŠ¤í† ë¦¬ ì €ì¥
        self._save_history()
    
    def clear_history(self):
        """ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        self.chat_history.clear()
        # íŒŒì¼ë„ ì‚­ì œ
        history_file = self._get_history_file_path()
        if history_file.exists():
            history_file.unlink()
            print(f"ğŸ—‘ï¸ ëŒ€í™” íˆìŠ¤í† ë¦¬ íŒŒì¼ ì‚­ì œ: {history_file.name}")
    
    def get_history(self) -> List[Dict[str, str]]:
        """ì±„íŒ… íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        return [
            {
                "role": msg.role,
                "content": msg.content,
                "timestamp": msg.timestamp
            }
            for msg in self.chat_history
        ]
    
    def get_session_info(self) -> Dict[str, Any]:
        """ì„¸ì…˜ ì •ë³´ ë°˜í™˜"""
        return {
            "session_id": self.session_id,
            "provider": self.provider,
            "message_count": len(self.chat_history),
            "storage_path": str(self._get_history_file_path()),
            "created_at": self.chat_history[0].timestamp if self.chat_history else None,
            "updated_at": self.chat_history[-1].timestamp if self.chat_history else None
        }
    
    @classmethod
    def list_sessions(cls, storage_dir: Optional[str] = None) -> List[Dict[str, Any]]:
        """ì €ì¥ëœ ëª¨ë“  ì„¸ì…˜ ëª©ë¡ ë°˜í™˜"""
        if storage_dir:
            storage_path = Path(storage_dir)
        else:
            backend_dir = Path(__file__).parent.parent
            storage_path = backend_dir / "chat_history"
        
        if not storage_path.exists():
            return []
        
        sessions = []
        for file in storage_path.glob("chat_*.json"):
            try:
                with open(file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    sessions.append({
                        "session_id": data.get("session_id"),
                        "provider": data.get("provider"),
                        "message_count": data.get("message_count", 0),
                        "created_at": data.get("created_at"),
                        "updated_at": data.get("updated_at"),
                        "file_path": str(file)
                    })
            except Exception as e:
                print(f"âš ï¸ ì„¸ì…˜ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({file.name}): {str(e)}")
        
        # ìµœì‹ ìˆœ ì •ë ¬
        sessions.sort(key=lambda x: x.get("updated_at", ""), reverse=True)
        return sessions
    
    @classmethod
    def load_session(cls, session_id: str, storage_dir: Optional[str] = None, **kwargs):
        """íŠ¹ì • ì„¸ì…˜ ë¡œë“œ"""
        return cls(session_id=session_id, storage_dir=storage_dir, **kwargs)
    
    def set_system_prompt(self, prompt: str):
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë³€ê²½"""
        self.system_prompt = prompt
        self.prompt = self._create_prompt_template()
        self.chain = self._create_chain()


class PortfolioAnalysisChat(ChatService):
    """í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ íŠ¹í™” ì±—ë´‡ (Document Loader ì‚¬ìš©)"""
    
    def __init__(
        self,
        portfolio_data: Optional[Dict] = None,
        provider: Literal["openai", "gemini"] = "gemini",
        model: Optional[str] = None,
        temperature: float = 0.7,
        session_id: Optional[str] = None,
        storage_dir: Optional[str] = None
    ):
        """
        PortfolioAnalysisChat ì´ˆê¸°í™”
        
        Args:
            portfolio_data: í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°
            provider: AI ì œê³µì
            model: ì‚¬ìš©í•  ëª¨ë¸ëª…
            temperature: ìƒì„± ì˜¨ë„
            session_id: ì„¸ì…˜ ID
            storage_dir: ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.portfolio_data = portfolio_data
        self.portfolio_document: Optional[Document] = None
        self.portfolio_markdown_path: Optional[Path] = None
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ìƒì„±
        if portfolio_data:
            self._generate_portfolio_document()
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° ê¸°ë°˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = self._create_portfolio_system_prompt()
        
        super().__init__(
            provider=provider,
            model=model,
            temperature=temperature,
            system_prompt=system_prompt,
            session_id=session_id,
            storage_dir=storage_dir
        )
    
    def _generate_portfolio_document(self):
        """í¬íŠ¸í´ë¦¬ì˜¤ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ìƒì„±"""
        try:
            from .portfolio_document import generate_portfolio_markdown, save_portfolio_markdown
            
            # ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ì €ì¥ ê²½ë¡œ
            backend_dir = Path(__file__).parent.parent
            docs_dir = backend_dir / "portfolio_docs"
            docs_dir.mkdir(parents=True, exist_ok=True)
            
            # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ìƒì„±
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            markdown_path = docs_dir / f"portfolio_{timestamp}.md"
            
            markdown_content = generate_portfolio_markdown(self.portfolio_data)
            
            with open(markdown_path, 'w', encoding='utf-8') as f:
                f.write(markdown_content)
            
            self.portfolio_markdown_path = markdown_path
            
            # Document ê°ì²´ ìƒì„±
            self.portfolio_document = Document(
                page_content=markdown_content,
                metadata={
                    "source": "portfolio_data",
                    "type": "markdown",
                    "generated_at": timestamp
                }
            )
            
            print(f"âœ… í¬íŠ¸í´ë¦¬ì˜¤ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ìƒì„±: {markdown_path}")
            
        except Exception as e:
            print(f"âš ï¸ í¬íŠ¸í´ë¦¬ì˜¤ ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            self.portfolio_document = None
    
    def _create_portfolio_system_prompt(self) -> str:
        """í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° ê¸°ë°˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        base_prompt = """ë‹¹ì‹ ì€ ì£¼ì‹ í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³ , íˆ¬ì ì „ëµì— ëŒ€í•œ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” ì—­í• :
1. í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ë¶„ì„
2. ìì‚° ë°°ë¶„ ì¡°ì–¸
3. ìœ„í—˜ ê´€ë¦¬ ì „ëµ ì œì•ˆ
4. íˆ¬ì ì„±ê³¼ í‰ê°€

í•­ìƒ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ë©°, íˆ¬ì ì¡°ì–¸ì€ ì°¸ê³ ìš©ì„ì„ ëª…ì‹œí•©ë‹ˆë‹¤."""
        
        if self.portfolio_document:
            # ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ë‚´ìš©ì„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
            portfolio_info = f"""

ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ ìƒì„¸í•œ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ì…ë‹ˆë‹¤:

---
{self.portfolio_document.page_content[:10000]}  
---

ìœ„ í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
ë°ì´í„°ì— ëª…ì‹œëœ ì •í™•í•œ ìˆ˜ì¹˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”."""
            
            base_prompt += portfolio_info
        elif self.portfolio_data:
            # ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨ ì‹œ ìš”ì•½ ì •ë³´ë§Œ ì‚¬ìš©
            summary = self.portfolio_data.get("portfolio_summary", {})
            if summary:
                total_value = summary.get("total_value", 0)
                total_investment = summary.get("total_investment", 0)
                total_gain_loss = summary.get("total_gain_loss", 0)
                total_gain_loss_rate = summary.get("total_gain_loss_rate", 0)
                
                portfolio_info = f"""

í˜„ì¬ ì‚¬ìš©ìì˜ í¬íŠ¸í´ë¦¬ì˜¤ ìš”ì•½:
- ì´ í‰ê°€ì•¡: â‚©{total_value:,.0f}
- ì´ íˆ¬ìê¸ˆ: â‚©{total_investment:,.0f}
- ì´ ì†ìµ: â‚©{total_gain_loss:,.0f} ({total_gain_loss_rate:.2f}%)

ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."""
                
                base_prompt += portfolio_info
        
        return base_prompt
    
    def update_portfolio_data(self, portfolio_data: Dict):
        """í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„° ì—…ë°ì´íŠ¸"""
        self.portfolio_data = portfolio_data
        
        # ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ ì¬ìƒì„±
        self._generate_portfolio_document()
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸
        self.set_system_prompt(self._create_portfolio_system_prompt())
    
    def analyze_portfolio(self) -> str:
        """í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ ë¶„ì„"""
        if not self.portfolio_data:
            return "í¬íŠ¸í´ë¦¬ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        analysis_prompt = """í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì „ì²´ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
ë‹¤ìŒ í•­ëª©ë“¤ì„ í¬í•¨í•´ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì „ì²´ ìˆ˜ìµë¥  í‰ê°€
2. ìì‚° ë°°ë¶„ í˜„í™©
3. ì£¼ìš” ë³´ìœ  ì¢…ëª© ë¶„ì„
4. ë¦¬ìŠ¤í¬ í‰ê°€
5. ê°œì„  ì œì•ˆ"""
        
        return self.chat(analysis_prompt)
    
    def get_investment_advice(self, question: str) -> str:
        """íˆ¬ì ì¡°ì–¸ ì œê³µ"""
        return self.chat(question)

